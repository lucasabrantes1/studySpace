{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visão Computacional\n",
    "\n",
    "## YOLO - You Only Look Once (Você Só Olha Uma Vez)\n",
    "Detector e Classificador de objetos\n",
    "\n",
    "* Usa Convolutional Neural Network - CNN, que é um ótimo classificador de imagens\n",
    "* Criado em Darknet, o framework criado por seus desenvolvedores\n",
    "* É capaz de detectar e classificar objetos em tempo real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO divide a imagem numa grid de 13 por 13 células:\n",
    "\n",
    "<img src=\"imagens/grid.png\" width=\"400px\" >\n",
    "\n",
    "Cada uma dessas células são resposáveis por fazer a predição de 5 caixas delimitadoras. Uma caixa delimitadora descreve um retângulo que engloba um objeto.\n",
    "\n",
    "YOLO também exibe um score de confiança que informa o quão certo ele está de que dentro da caixa delimitadora existe um objeto.\n",
    "\n",
    "<img src=\"imagens/boxes.png\" width=\"400px\" >\n",
    "\n",
    "Para cada caixa delimitadora, a célula também prever uma Classe. Essa parte funciona exatamente como qualquer outro Classificador: gera a probabilidade de que seja uma Classe do universo de classes que ele conhece.\n",
    "\n",
    "Classes como:\n",
    "\n",
    "* bicicleta\n",
    "* barco\n",
    "* carro\n",
    "* gato\n",
    "* cachorro\n",
    "* pessoa\n",
    "* e assim por diante…\n",
    "\n",
    "O score de confiança para uma caixa delimitadora e a predição da classe são combinados num único score final que nos diz a probabilidade de que uma caixa delimitadora contém um objeto de um tipo específico, por exemplo \"cachorro\":\n",
    "\n",
    "<img src=\"imagens/scores.png\" width=\"400px\" >\n",
    "\n",
    "Uma vez que existe uma grid de 13x13 = 169 células, e cada uma das céluas fazem a predição de 5 caixas delimitadoras, obtém-se 845 caixas delimitadoras no total. E naturalmente a grande maioria dessas caixas terão um score de confiança muito pequeno, de forma que as únicas caixas que permanecem são as que possuem 30% ou mais de score de confiança (é possível modificar esse limite dependendo de quão acurado você deseja que o detector seja).\n",
    "\n",
    "A predição final é:\n",
    "\n",
    "<img src=\"imagens/pred.png\" width=\"400px\" >\n",
    "\n",
    "YOLO usa uma tecnica de normalização chamada de _batch normalization_ depois das camadas do modelo Convolucional. A figura a seguir é um exemplo real onde a primeira imagem é da primeira camada convolucional sem _batch normalization_ e a segunda com:\n",
    "\n",
    "<img src=\"imagens/batch.png\" width=\"400px\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloads:\n",
    "* http://bit.ly/yolov3weights\n",
    "* http://bit.ly/yolov3_projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fontes:\n",
    "\n",
    "* https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/\n",
    "* https://pjreddie.com/darknet/yolo/\n",
    "* http://machinethink.net/blog/object-detection-with-yolo/\n",
    "* https://github.com/pjreddie/darknet/wiki/YOLO:-Real-Time-Object-Detection\n",
    "* https://medium.com/@xslittlegrass/almost-real-time-vehicle-detection-using-yolo-da0f016b43de\n",
    "* https://github.com/KleinYuan/easy-yolo\n",
    "* https://medium.com/diaryofawannapreneur/yolo-you-only-look-once-for-object-detection-explained-6f80ea7aaa1e\n",
    "* https://www.youtube.com/watch?v=TgeX-AF7_DE\n",
    "* https://www.youtube.com/watch?v=HbD9e6-qzko\n",
    "* https://www.youtube.com/watch?v=SO4tjI43Ob4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
